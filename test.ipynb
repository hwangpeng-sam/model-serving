{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conti_model import MultiSeqBase\n",
    "model = MultiSeqBase(hidden_size = 16, embedding_dim = 4, dropout_p = 0.2)\n",
    "optim = torch.optim.Adam(model.parameters(), weight_decay=1e-3)\n",
    "\n",
    "checkpoint = torch.load('test_model_and_optimizer_conti.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optim.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiSeqBase' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49msave(model, \u001b[39m'\u001b[39;49m\u001b[39mmodel.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\058\\anaconda3\\envs\\ai_env\\lib\\site-packages\\torch\\jit\\_serialization.py:80\u001b[0m, in \u001b[0;36msave\u001b[1;34m(m, f, _extra_files)\u001b[0m\n\u001b[0;32m     78\u001b[0m     _extra_files \u001b[39m=\u001b[39m {}\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPath)):\n\u001b[1;32m---> 80\u001b[0m     m\u001b[39m.\u001b[39;49msave(f, _extra_files\u001b[39m=\u001b[39m_extra_files)\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     ret \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39msave_to_buffer(_extra_files\u001b[39m=\u001b[39m_extra_files)\n",
      "File \u001b[1;32mc:\\Users\\058\\anaconda3\\envs\\ai_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiSeqBase' object has no attribute 'save'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiSeqBase:\n\tsize mismatch for lstm_r1.weight_ih_l0: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([128, 1]).\n\tsize mismatch for lstm_r1.weight_hh_l0: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for lstm_r1.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for lstm_r1.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_r1.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([16, 32]).\n\tsize mismatch for lstm_h1.weight_ih_l0: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([128, 1]).\n\tsize mismatch for lstm_h1.weight_hh_l0: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for lstm_h1.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for lstm_h1.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_h1.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([16, 32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m load_model()\n\u001b[0;32m      5\u001b[0m r_seq \u001b[39m=\u001b[39m db2Rseq()\n\u001b[0;32m      6\u001b[0m h_seq \u001b[39m=\u001b[39m db2Hseq(h_step \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m, pred_step \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\model-serving\\utils.py:147\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    144\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[0;32m    146\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtest_model_and_optimizer_conti.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 147\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    148\u001b[0m optim\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39moptimizer_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\058\\anaconda3\\envs\\ai_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiSeqBase:\n\tsize mismatch for lstm_r1.weight_ih_l0: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([128, 1]).\n\tsize mismatch for lstm_r1.weight_hh_l0: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for lstm_r1.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for lstm_r1.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_r1.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([16, 32]).\n\tsize mismatch for lstm_h1.weight_ih_l0: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([128, 1]).\n\tsize mismatch for lstm_h1.weight_hh_l0: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 32]).\n\tsize mismatch for lstm_h1.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for lstm_h1.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_h1.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([16, 32])."
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "   \n",
    "r_seq = db2Rseq()\n",
    "h_seq = db2Hseq(h_step = 4, pred_step = 6)\n",
    "t = dt2T(pred_step = 6)\n",
    "s_attrs, _ = db2S()\n",
    "\n",
    "# output = model(r_seq.float(), h_seq.float(), t.int(), s_attrs.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time: 0.08759307861328125\n",
      "time: 1692321029.1656742 summation: 369411\n"
     ]
    }
   ],
   "source": [
    "# test for lambda\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "now = time.time()\n",
    "connection = db_connect()\n",
    "select_query = \"SELECT * FROM occupancy\"\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "        cursor.execute(select_query)\n",
    "        result = cursor.fetchall()\n",
    "        connection.close()\n",
    "\n",
    "df = pd.DataFrame(result, columns=[col[0] for col in cursor.description])\n",
    "\n",
    "print('running time:', time.time() - now)\n",
    "print('time:', now, 'summation:', df.sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
