{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "models = []\n",
    "for _ in range(4):\n",
    "    models.append(torch.jit.load('MultiSeqUmapEmb_epoch-100_pred_step-6_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "r_seq = db2Rseq()\n",
    "h_seq = db2Hseq(h_step = 4)\n",
    "t = dt2T()\n",
    "s_attrs, _ = db2S()\n",
    "\n",
    "pred_steps = [1, 2, 3, 6]\n",
    "\n",
    "# model inference\n",
    "for i, m in enumerate(pred_steps):\n",
    "    globals()[f'res_{m}'] = torch.exp(models[i](r_seq.float(), h_seq[:, i, :, :].float(), t[:, i, :].int(), s_attrs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1278, 0.2522, 0.6200],\n",
       "        [0.1248, 0.6716, 0.2036],\n",
       "        [0.1840, 0.5177, 0.2982],\n",
       "        ...,\n",
       "        [1.0000, 0.0000, 0.0000],\n",
       "        [0.4062, 0.3293, 0.2644],\n",
       "        [0.9779, 0.0072, 0.0149]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
