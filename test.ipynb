{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def test():\n",
    "\n",
    "    # Load model\n",
    "    model = torch.jit.load('model.pt')\n",
    "    \n",
    "    # import input from database\n",
    "    r_seq = db2Rseq()\n",
    "    h_seq = db2Hseq(h_step = 4)\n",
    "    t = dt2T()\n",
    "    s_attrs, _ = db2S()\n",
    "\n",
    "    # model inference\n",
    "    minutes = [20, 40, 60, 120]\n",
    "\n",
    "    for i, m in enumerate(minutes):\n",
    "        globals()[f'res_{m}'] = model(r_seq.float(), h_seq[:, i, :, :].float(), t[:, i, :].int(), s_attrs.float())\n",
    "\n",
    "    # export output to database\n",
    "    outputs = torch.hstack([res_20, res_40, res_60, res_120])\n",
    "\n",
    "    try:\n",
    "        y2db(outputs) \n",
    "        return {'time':get_now(), 'status':'Success'}\n",
    "\n",
    "    except: return {'time': get_now(), 'status':'Failed'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2023-08-21 13:00:00', 'status': 'Success'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve encoding error in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from conti_model import MultiSeqBase\n",
    "\n",
    "# load model\n",
    "model = MultiSeqBase(hidden_size = 16, embedding_dim = 4, dropout_p = 0.2)\n",
    "optim = torch.optim.Adam(model.parameters(), weight_decay=1e-3)\n",
    "\n",
    "checkpoint = torch.load('test_model_and_optimizer_conti.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optim.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiSeqBase(\n",
       "  (lstm_r1): LSTM(1, 16, batch_first=True)\n",
       "  (fc_r1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (lstm_h1): LSTM(1, 16, batch_first=True)\n",
       "  (fc_h1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (timeslot_embedding): Embedding(144, 4)\n",
       "  (dow_embedding): Embedding(7, 4)\n",
       "  (we_embedding): Embedding(2, 4)\n",
       "  (fc_b1): Linear(in_features=12, out_features=128, bias=True)\n",
       "  (fc_b2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc_b3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc_cat): Linear(in_features=96, out_features=64, bias=True)\n",
       "  (top): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.jit.load('model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
