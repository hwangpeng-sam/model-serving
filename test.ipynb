{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.jit.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def test():\n",
    "    # Load model\n",
    "\n",
    "    # load model from s3\n",
    "    # s3 = boto3.client('s3')\n",
    "    # bucket_name = 'your_bucket_name'\n",
    "    # object_key = 'your_object_key'\n",
    "\n",
    "    # response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    # data = response['Body'].read()\n",
    "\n",
    "    # save model to local\n",
    "    # with open('/tmp/model.pt', 'wb') as file:\n",
    "    #     file.write(data)\n",
    "\n",
    "    # load model from local\n",
    "    # model = torch.jit.load('/tmp/model.pt')\n",
    "    model = torch.jit.load('model.pt')\n",
    "    \n",
    "    # import input from database\n",
    "    r_seq = db2Rseq()\n",
    "    h_seq = db2Hseq(h_step = 4)\n",
    "    t = dt2T()\n",
    "    s_attrs, _ = db2S()\n",
    "\n",
    "    # model inference\n",
    "    minutes = [20, 40, 60, 120]\n",
    "\n",
    "    for i, m in enumerate(minutes):\n",
    "        globals()[f'res_{m}'] = model(r_seq.float(), h_seq[:, i, :, :].float(), t[:, i, :].int(), s_attrs.float())\n",
    "\n",
    "    # export output to database\n",
    "    now = db2Now()\n",
    "    outputs = torch.hstack([now, res_20, res_40, res_60, res_120])\n",
    "\n",
    "    try:\n",
    "        y2db(outputs) \n",
    "        return {'status':'Success', 'time': f'{get_now()}'}\n",
    "\n",
    "    except: return {'status':'Failed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Success', 'time': '2023-08-24 10:20:00'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "model = torch.jit.load('model.pt')\n",
    "    \n",
    "# import input from database\n",
    "r_seq = db2Rseq()\n",
    "h_seq = db2Hseq(h_step = 4)\n",
    "t = dt2T()\n",
    "s_attrs, _ = db2S()\n",
    "\n",
    "# model inference\n",
    "minutes = [20, 40, 60, 120]\n",
    "\n",
    "for i, m in enumerate(minutes):\n",
    "    globals()[f'res_{m}'] = model(r_seq.float(), h_seq[:, i, :, :].float(), t[:, i, :].int(), s_attrs.float())\n",
    "\n",
    "# export output to database\n",
    "now = db2Now()\n",
    "outputs = torch.hstack([now, res_20, res_40, res_60, res_120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -5.3852e-03, -5.6336e+00,  ..., -5.3852e-03,\n",
       "         -5.6336e+00, -6.3228e+00],\n",
       "        [ 2.0000e+00, -7.9920e-01, -1.8177e+00,  ..., -7.9920e-01,\n",
       "         -1.8177e+00, -9.4698e-01],\n",
       "        [ 2.0000e+00, -8.3606e-01, -1.8029e+00,  ..., -8.3606e-01,\n",
       "         -1.8029e+00, -9.1189e-01],\n",
       "        ...,\n",
       "        [ 0.0000e+00, -5.1188e-03, -5.6792e+00,  ..., -5.1188e-03,\n",
       "         -5.6792e+00, -6.3833e+00],\n",
       "        [ 0.0000e+00, -5.1188e-03, -5.6792e+00,  ..., -5.1188e-03,\n",
       "         -5.6792e+00, -6.3833e+00],\n",
       "        [ 0.0000e+00, -5.1188e-03, -5.6792e+00,  ..., -5.1188e-03,\n",
       "         -5.6792e+00, -6.3833e+00]], dtype=torch.float64,\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
